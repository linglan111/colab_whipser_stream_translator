{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linglan111/colab_whipser_stream_translator/blob/main/%E2%80%9Ccolab_whipser_stream_translator_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ä½¿ç”¨colabäº‘ç«¯è¿è¡Œè‡ªåŠ¨å­—å¹•ç¨‹åº\n"
      ],
      "metadata": {
        "id": "Lbja1jB3vDOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ç¬¬ä¸€æ­¥ä»githubä¸Šå°†è¦ç”¨åˆ°çš„é¡¹ç›®å¤åˆ¶ä¸‹æ¥\n",
        "è¿™é‡Œå‰é¢çš„!æ˜¯ä¸ºäº†å‘Šè¯‰colab\n",
        "**è¿™ä¸€æ­¥æˆ‘ä»¬ç”¨çš„æ˜¯shellå‘½ä»¤è€Œä¸æ˜¯pythonè¯­å¥**"
      ],
      "metadata": {
        "id": "dSJ6EpRAbRZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fortypercnt/stream-translator.git"
      ],
      "metadata": {
        "id": "JyWu-c57JdGH",
        "outputId": "fd148b27-77cc-4775-a800-84a82d320d91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stream-translator'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 69 (delta 34), reused 29 (delta 29), pack-reused 31\u001b[K\n",
            "Unpacking objects: 100% (69/69), 1.19 MiB | 1.04 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä¸‹ä¸€æ­¥å®‰è£…ä¾èµ–"
      ],
      "metadata": {
        "id": "uaA0w3BkdJ4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/stream-translator/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz0JHOwwdHUH",
        "outputId": "140fb97a-6c61-42a3-e555-988d68b437d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Collecting git+https://github.com/openai/whisper.git (from -r /content/stream-translator/requirements.txt (line 8))\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-y8d0djf_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-y8d0djf_\n",
            "  Resolved https://github.com/openai/whisper.git to commit 248b6cb124225dd263bb9bd32d060b6517e067f8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r /content/stream-translator/requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /content/stream-translator/requirements.txt (line 2)) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from -r /content/stream-translator/requirements.txt (line 3)) (9.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r /content/stream-translator/requirements.txt (line 5)) (2.0.1+cu118)\n",
            "Collecting transformers>=4.19.0 (from -r /content/stream-translator/requirements.txt (line 6))\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0 (from -r /content/stream-translator/requirements.txt (line 7))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting streamlink (from -r /content/stream-translator/requirements.txt (line 9))\n",
            "  Downloading streamlink-5.5.1-py3-none-any.whl (362 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m362.5/362.5 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->-r /content/stream-translator/requirements.txt (line 7)) (0.18.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/stream-translator/requirements.txt (line 5)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/stream-translator/requirements.txt (line 5)) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/stream-translator/requirements.txt (line 5)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/stream-translator/requirements.txt (line 5)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/stream-translator/requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/stream-translator/requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r /content/stream-translator/requirements.txt (line 5)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r /content/stream-translator/requirements.txt (line 5)) (16.0.6)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6))\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6))\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314->-r /content/stream-translator/requirements.txt (line 8)) (0.56.4)\n",
            "Collecting tiktoken==0.3.3 (from openai-whisper==20230314->-r /content/stream-translator/requirements.txt (line 8))\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from streamlink->-r /content/stream-translator/requirements.txt (line 9)) (2023.5.7)\n",
            "Collecting isodate (from streamlink->-r /content/stream-translator/requirements.txt (line 9))\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml<5.0,>=4.6.4 in /usr/local/lib/python3.10/dist-packages (from streamlink->-r /content/stream-translator/requirements.txt (line 9)) (4.9.2)\n",
            "Collecting pycountry (from streamlink->-r /content/stream-translator/requirements.txt (line 9))\n",
            "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome<4,>=3.4.3 (from streamlink->-r /content/stream-translator/requirements.txt (line 9))\n",
            "  Downloading pycryptodome-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from streamlink->-r /content/stream-translator/requirements.txt (line 9)) (1.7.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from streamlink->-r /content/stream-translator/requirements.txt (line 9)) (1.26.16)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from streamlink->-r /content/stream-translator/requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (3.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate->streamlink->-r /content/stream-translator/requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r /content/stream-translator/requirements.txt (line 5)) (2.1.3)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314->-r /content/stream-translator/requirements.txt (line 8)) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314->-r /content/stream-translator/requirements.txt (line 8)) (67.7.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r /content/stream-translator/requirements.txt (line 5)) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper, pycountry\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798075 sha256=f9a3878d68ed37adb292c4f0d59293da672693a0f75665d7634d8b849776739d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m4ezgvzl/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "  Building wheel for pycountry (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681832 sha256=f03709e82c6b36755bf2f3fc083f5488912bcea2d3a327f9c6cbab89e4f028b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/57/cc/290c5252ec97a6d78d36479a3c5e5ecc76318afcb241ad9dbe\n",
            "Successfully built openai-whisper pycountry\n",
            "Installing collected packages: tokenizers, safetensors, pycryptodome, pycountry, isodate, ffmpeg-python, tiktoken, streamlink, huggingface-hub, transformers, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.15.1 isodate-0.6.1 openai-whisper-20230314 pycountry-22.3.5 pycryptodome-3.18.0 safetensors-0.3.1 streamlink-5.5.1 tiktoken-0.3.3 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ä¿®æ”¹å·¥ä½œ"
      ],
      "metadata": {
        "id": "Z6_hXwR9ajWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™é‡Œæœ‰ä¸€ä¸ªå°å‘\n",
        "æˆ‘ä»¬å…ˆå°è¯•ä¸åšä»»ä½•æ”¹åŠ¨ç›´æ¥è¿è¡Œç¨‹åº\n",
        "ä¼šå‘ç°åœ¨æ¨¡å‹ä¸‹è½½å¥½ä¹‹åç›´æ¥æŠ¥é”™æ‰¾ä¸åˆ°æŒ‡å®šæ–‡ä»¶\n",
        "ValueError: The provided filename silero_vad.jit does not exist"
      ],
      "metadata": {
        "id": "G5ltjG3Idz8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 stream-translator/translator.py https://www.youtube.com/watch?v=swe6ea_9P2s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs8mszjbd6zg",
        "outputId": "8e7b6bb9-5f50-409f-a3f8-af22026d2bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461M/461M [00:09<00:00, 50.7MiB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"stream-translator/translator.py\", line 226, in <module>\n",
            "    cli()\n",
            "  File \"stream-translator/translator.py\", line 222, in cli\n",
            "    main(url, **args)\n",
            "  File \"stream-translator/translator.py\", line 117, in main\n",
            "    vad = VAD()\n",
            "  File \"/content/stream-translator/vad.py\", line 9, in __init__\n",
            "    self.model = init_jit_model(\"silero_vad.jit\")\n",
            "  File \"/content/stream-translator/vad.py\", line 20, in init_jit_model\n",
            "    model = torch.jit.load(model_path, map_location=device)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/jit/_serialization.py\", line 152, in load\n",
            "    raise ValueError(\"The provided filename {} does not exist\".format(f))  # type: ignore[str-bytes-safe]\n",
            "ValueError: The provided filename silero_vad.jit does not exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ç‚¹å‡»å·¦ä¾§çš„æ–‡ä»¶å¤¹ğŸ“‚\n",
        "é€‰æ‹©stream-translator\n",
        "å³é”®silero_vad.jitè·å–æ–‡ä»¶åœ°å€\n",
        "åŒå‡»vad.pyå¯ä»¥çœ‹åˆ°å³ä¾§æ‰“å¼€äº†ä¸€ä¸ªåœ¨çº¿ç¼–è¾‘é¡µé¢\n",
        "æˆ‘ä»¬åœ¨ç¬¬9è¡Œå°†init_jit_modelåé¢æ‹¬å·é‡Œçš„å†…å®¹\n",
        "æ”¹ä¸ºåˆšæ‰å¤åˆ¶çš„æ–‡ä»¶åœ°å€\n",
        "ç„¶åctrl+sä¿å­˜åå…³é—­æ–‡ä»¶\n",
        "è¿™é‡Œæ˜¯å› ä¸ºcolabç›´æ¥gitä¸‹æ¥çš„é¡¹ç›®\n",
        "è¿è¡Œçš„æ—¶å€™è¿™é‡Œä¼šå‡ºç°æ— æ³•æŒ‡å®šåˆ°æ­£ç¡®è·¯å¾„çš„é—®é¢˜\n",
        "æ‰€ä»¥éœ€è¦æ‰‹åŠ¨æ”¹ä¸ºç»å¯¹è·¯å¾„"
      ],
      "metadata": {
        "id": "zuHOPp8catS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#å¼€å§‹è¿è¡Œ"
      ],
      "metadata": {
        "id": "jeIZ3okhao8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ç½‘å€æ”¹ä¸ºä½ æƒ³è¦å®æ—¶è½¬å½•çš„ç›´æ’­\n",
        "ç†è®ºä¸Šæ¥è¯´åªè¦streamlinkæ”¯æŒçš„ç½‘ç«™éƒ½å¯ä»¥"
      ],
      "metadata": {
        "id": "vx5Y_Mf5cXs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 stream-translator/translator.py https://www.youtube.com/watch?v=HL5WsJBsp4o"
      ],
      "metadata": {
        "id": "scuUKqmEV7-U",
        "outputId": "da53f943-bd88-4193-d258-9887bdaaee62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461M/461M [00:07<00:00, 63.5MiB/s]\n",
            "Opening stream...\n",
            "[cli][info] streamlink is running as root! Be careful!\n",
            "[cli][info] Found matching plugin youtube for URL https://www.youtube.com/watch?v=HL5WsJBsp4o\n",
            "[cli][info] Available streams: 144p (worst), 240p, 360p, 480p, 720p, 1080p (best)\n",
            "[cli][info] Opening stream: 1080p (hls)\n",
            "06:05:43 (ja)  Oh no! Wait, isn't this a road car?\n",
            "06:05:44 (ja)  Next, I'm the king! The queen!\n",
            "06:05:49 (ja)  You're pretty cakey! I'll deal with you! Ok!\n",
            "06:05:54 (ja)  How can I have anger on women? How can I have hope on women?\n",
            "06:06:05 (ja)  Yeah, that's rightâ€‹\n",
            "06:06:07 (ja)  Naoto-kun! Naoto-kun! Naoto-kun! Naoto-kun!\n",
            "06:06:07 (ja)  What?\n",
            "06:06:09 (ja)  If I talk to you, I'll let you know something.\n",
            "06:06:10 (ja)  I don't care. I don't care. I don't care.\n",
            "06:06:16 (ja)  It's your fault!\n",
            "06:06:20 (ja)  What is it?\n",
            "06:06:26 (ja) \n",
            "06:06:31 (ja)  Yeah.\n",
            "06:06:39 (ja)  That's awesome!\n",
            "06:06:40 (ja)  I feel like I'm in the middle of something. You're right, it's like you're in the middle of something.\n",
            "06:06:46 (ja)  In the past, there was no scientific research.\n",
            "06:06:50 (ja)  Hmm.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¿½ç•¥ç»“å°¾å› æ‰‹åŠ¨æš‚åœè€Œäº§ç”Ÿçš„æŠ¥é”™ä¿¡æ¯\n",
        "è½¬å½•å‡ºçš„ç»“æœçœ‹èµ·æ¥è¿˜æ˜¯æœ‰äº›æ€ªæ€ªçš„\n",
        "æˆ‘ä»¬ä¸€ä¸ªä¸ªè§£å†³\n",
        "\n",
        "\n",
        "*   **è½¬å½•å‡ºæ¥çš„ä¸œè¥¿æ˜¯è‹±æ–‡**\n",
        "è¿™æ˜¯å› ä¸ºstream_translatorçš„ä½œè€…é»˜è®¤è®¾ç½®çš„æ˜¯å¼€å¯è‹±æ–‡ç¿»è¯‘\n",
        "è¿è¡Œçš„æ—¶å€™éœ€è¦åœ¨åé¢åŠ ä¸Šå‚æ•° --task transcribe\n",
        "*   **æœ‰æ—¶å€™è¯†åˆ«å‡ºæ¥çš„è¯­ç§å¹¶ä¸æ˜¯ä¸»æ’­è¯´çš„**\n",
        "è¯­è¨€å‚æ•°é»˜è®¤ä¸ºauto\n",
        "ä¹Ÿå°±æ˜¯æ¯ä¸€å¥éƒ½æ˜¯è‡ªåŠ¨è¯†åˆ«è¯­ç§\n",
        "æ›´æ”¹ä¸ºæŒ‡å®šè¯­è¨€å¯ä»¥è§£å†³è¿™ä¸€é—®é¢˜\n",
        "*   **ä¸å¤Ÿç²¾å‡†**\n",
        "æ¨¡å‹å‚æ•°é»˜è®¤ä¸ºsmall\n",
        "æ—¢ç„¶ç™½å«–colabçš„GPUï¼Œæˆ‘ä»¬å¯ä»¥ä¿®æ”¹ä¸ºmediumç”šè‡³largeğŸ˜€\n",
        " *å®é™…è½¬å½•ä¸­å‡ºç°äº†è®¾ç½®æ¨¡å‹è¿‡å¤§çš„æ—¶å€™æ— æ³•æ­£å¸¸è½¬å½•çš„æƒ…å†µåˆæ­¥åˆ¤æ–­åº”è¯¥æ˜¯å†…å­˜ä¸å¤Ÿçš„é—®é¢˜*\n",
        "*   **å¯¼å…¥çš„æµæ˜¯1080Pæ‹…å¿ƒå½±å“è½¬å½•é€Ÿåº¦**\n",
        "æ­£å¸¸æ¥è¯´ffmpegä¼šè‡ªåŠ¨åˆ†ç¦»å‡ºéŸ³é¢‘æµæ‰€ä»¥å½±å“ä¸å¤§\n",
        "å¦‚æœè¿˜æ˜¯æ€•1080Pçš„ç›´æ’­åˆ†ç‰‡ä¸‹è½½ä¼šå¡\n",
        "è¿™é‡Œå¯ä»¥æ‰‹åŠ¨å»é…ç½®æ–‡ä»¶ä¿®æ”¹ä¸ºworstæ‹‰å–144pçš„æµ\n",
        "ä½œè€…é»˜è®¤çš„audio_onlyå‚æ•°å¯¹äºyoutubeç›´æ’­æ˜¯æ— æ•ˆçš„\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jBPFRC43fD5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "åœ¨ä¸Šä¸€æ¬¡æ›¾ç»æ‰“å¼€çš„æ–‡ä»¶å¤¹é‡Œæ‰¾åˆ°translator.pyæ–‡ä»¶\n",
        "åŒå‡»æ‰“å¼€å®šä½åˆ°167è¡Œdef cli()è¿™ä¸ªå‡½æ•°é‡Œ\n",
        "é‡Œé¢æ‰€æœ‰defaultå¯¹åº”çš„å€¼å°±æ˜¯é»˜è®¤å€¼\n",
        "æŒ‰ç…§ä¸Šé¢çš„éœ€æ±‚æˆ‘ä»¬å¯ä»¥æŒ‰ç…§å¦‚ä¸‹ä¿®æ”¹\n",
        "--model medium\n",
        "--task transcribe\n",
        "--language Japaneseï¼ˆæŒ‰ç…§å®é™…éœ€æ±‚ï¼‰\n",
        "--preferred_quality worst\n",
        "é‡æ–°è·‘ä¸€éè¯•è¯•çœ‹å§ï¼\n",
        "æ³¨æ„åŠ å…¥æ–°æ¨¡å‹çš„æ—¶å€™è¦å…ˆä¸‹è½½"
      ],
      "metadata": {
        "id": "tvBpp56BhxSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!pip install \"faster-whisper @ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz\"\n",
        "!ct2-transformers-converter --model openai/whisper-large-v2 --output_dir whisper-large-v2-ct2 \\\n",
        "    --copy_files tokenizer.json --quantization float16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ftx7ROuX4vf",
        "outputId": "1123ea61-2963-40fa-ccfb-e9ddb5f25019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz\n",
            "  Downloading https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz\n",
            "\u001b[2K     \u001b[32m/\u001b[0m \u001b[32m2.9 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av==10.* (from faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctranslate2<4,>=3.10 (from faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading ctranslate2-3.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (0.15.1)\n",
            "Requirement already satisfied: tokenizers==0.13.* in /usr/local/lib/python3.10/dist-packages (from faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (0.13.3)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m118.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.10->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (1.22.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.10->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (4.6.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (23.1)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (1.11.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (1.3.0)\n",
            "Building wheels for collected packages: faster-whisper\n",
            "  Building wheel for faster-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for faster-whisper: filename=faster_whisper-0.6.0-py3-none-any.whl size=1537994 sha256=daa3484e565befef20d9c389b0befbff5d2a93bb30c80da5f73ee53c27c28ae2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zzl3xly3/wheels/b6/35/41/e289a1c8f68133f6b89dab0a3883dd5183cab41a321567010d\n",
            "Successfully built faster-whisper\n",
            "Installing collected packages: av, humanfriendly, ctranslate2, coloredlogs, onnxruntime, faster-whisper\n",
            "Successfully installed av-10.0.0 coloredlogs-15.0.1 ctranslate2-3.16.0 faster-whisper-0.6.0 humanfriendly-10.0 onnxruntime-1.15.1\n",
            "Downloading (â€¦)lve/main/config.json: 1.99kB [00:00, 7.59MB/s]\n",
            "Downloading pytorch_model.bin: 100% 6.17G/6.17G [00:35<00:00, 175MB/s]\n",
            "Downloading (â€¦)neration_config.json: 3.51kB [00:00, 1.12MB/s]\n",
            "Downloading (â€¦)okenizer_config.json: 100% 800/800 [00:00<00:00, 1.64MB/s]\n",
            "Downloading (â€¦)olve/main/vocab.json: 836kB [00:00, 1.33MB/s]\n",
            "Downloading (â€¦)/main/tokenizer.json: 2.20MB [00:00, 2.53MB/s]\n",
            "Downloading (â€¦)olve/main/merges.txt: 494kB [00:00, 1.14MB/s]\n",
            "Downloading (â€¦)main/normalizer.json: 52.7kB [00:00, 29.2MB/s]\n",
            "Downloading (â€¦)in/added_tokens.json: 2.08kB [00:00, 8.05MB/s]\n",
            "Downloading (â€¦)cial_tokens_map.json: 2.08kB [00:00, 7.23MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stream-translator/\n",
        "!git clone https://github.com/neverneverendup/Translator.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gggy8EWfMqZy",
        "outputId": "222fa4d9-e13e-4196-907b-8bb493305a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stream-translator\n",
            "Cloning into 'Translator'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 34 (delta 15), reused 7 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), 14.95 KiB | 1.36 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!python3 stream-translator/translator.py https://www.youtube.com/watch?v=y5M6OZKhJjI --model large --task transcribe --language ja \\\n",
        "  --use_faster_whisper --faster_whisper_model_path /content/whisper-large-v2-ct2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES05tKOuic4X",
        "outputId": "c967bb95-b27e-4ee9-a032-1a9c718bc641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Loading model...\n",
            "Opening stream...\n",
            "[cli][info] streamlink is running as root! Be careful!\n",
            "[cli][info] Found matching plugin youtube for URL https://www.youtube.com/watch?v=y5M6OZKhJjI\n",
            "[cli][info] Available streams: 144p (worst), 240p, 360p, 480p, 720p, 1080p (best)\n",
            "[cli][info] Opening stream: 1080p (hls)\n",
            "07:39:59  ã„ã‚„ãƒ¼ãƒªã‚¼æ§˜ãšã£ã¨ã—ã‚“ã©ã‹ã£ãŸæœ¬å½“ã«å˜˜ã ã£ãŸ\n",
            "ä¸ï¼Œé‡Œæ³½è¨ç›çœŸçš„æ˜¯è°è¨€ã€‚\n",
            "07:40:01  ã€ã¯ã˜ã‚ã—ã‚ƒã¡ã‚‡ãƒ¼ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã€‘\n",
            "ã€åˆæ²™ç”ºç»“å±€ã€‘\n",
            "07:40:05  ã‚“?ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ã®åŠ¹æœã¿ãŸã„ãªã‚ã‚\n",
            "å—¯ï¼Ÿ è¿™å°±åƒæ˜µç§°çš„æ•ˆæœã€‚\n",
            "07:40:13  ã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„å‡ºãŸãã®ç†è«–ç†è«–ã‚ã‚‹ã‚ã‚‹ã‚ã‚‹åå‰ã‹ã‚‰ç†è«–\n",
            "å¯èƒ½æœ‰ä¸€ç§ç†è®ºè®¤ä¸ºç†è®ºæ˜¯ä»ä¸€äº›åå­—ä¸­å‡ºæ¥çš„\n",
            "07:40:16  ã—ã‚“ãã‚…ã‚“ å¹¸é‹æ—ãŒã—ã‚“ãã‚…ã‚“ å¼·ã„ã‹ã‚‰ã—ã‚“ãã‚…ã‚“ å¹¸é‹ã—ã‚“ãã‚…ã‚“ å¹¸é‹æ—\n",
            "æ–°å‡å¹¸è¿éƒ¨è½ æ–°å‡å¼ºå¡æ‹‰ æ–°å‡ ç¥ä½ å¥½è¿ æ–°å‡å¹¸è¿éƒ¨è½\n",
            "07:40:21  ã§ã‚‚ã†ã¡ã®ç›£ç£ã€ã‚­ãƒ§ã‚¦ã‚¦ãƒ³ã§ã™ã‘ã©ã‚‚ã£ã¦åå‰å¤‰ãˆã¦ã¦2ä½ã ã£ãŸã‹ãª\n",
            "ä½†æ˜¯æˆ‘çš„æ•™ç»ƒKyounæ”¹äº†åå­—ï¼Œè·å¾—äº†ç¬¬äºŒåã€‚\n",
            "07:40:33  ãºã‘ãŸã‚“ ã„ã‚„ãã‚Œã ã‹ã‚‰ãªã‹ã£ãŸã‚‰4ä½ã ã‹ã‚‰ãºã‘ãŸã‚“ ç¬‘\n",
            "ä½©å…‹å¦ ä¸ï¼Œå¦‚æœä¸æ˜¯è¿™æ ·ï¼Œæˆ‘ä¼šæ’åœ¨ç¬¬å››ä½ï¼Œå“ˆå“ˆã€‚\n",
            "07:40:35  ã‚ã„ã¤ã‚’ãã‚“ãªã€ä¸Šã«è¦‹ãªãã¦ã„ã„ã‚ˆã€ã‚ã„ã¤ã‚’\n",
            "ä½ ä¸å¿…é‚£æ ·çœ‹ç€ä»–ï¼Œ\n",
            "07:40:38  ã‚ã„ã¤ã¯å®ŸåŠ›ãŒ4ä½ã ã‹ã‚‰ã“ã®å‹•ç”»ã®å­—å¹•ã¯è¦–è´è€…ã«ã‚ˆã£ã¦ä½œæˆã•ã‚Œã¾ã—ãŸã€‚\n",
            "ä»–æ’åç¬¬å››ï¼Œæ‰€ä»¥è¿™ä¸ªè§†é¢‘çš„å­—å¹•æ˜¯ç”±è§‚ä¼—åˆ›å»ºçš„ã€‚\n",
            "07:40:42  ã‚ã®åå‰ã®ãŠã‹ã’ã§ã†ã¡ã®ç›£ç£ã«å³ã—ã„ã‚ˆ\n",
            "å› ä¸ºè¿™ä¸ªåå­—ï¼Œæˆ‘å¯¹æˆ‘çš„æ•™ç»ƒå¾ˆä¸¥å‰ã€‚\n",
            "07:40:45  èµ¤ã¡ã‚ƒã‚“ãã‚‰ã„ã—ã‹å³ã—ãã™ã‚‹äººã„ãªã„ã‹ã‚‰\n",
            "å› ä¸ºæ²¡æœ‰äººåƒå©´å„¿ä¸€æ ·ä¸¥æ ¼\n",
            "07:40:51  ã¿ã‚“ãªã‚‚ã£ã¦ãƒã«ç”˜ã„ã‹ã‚‰\n",
            "å› ä¸ºæ¯ä¸ªäººéƒ½é‚£ä¹ˆç”œèœœ\n",
            "07:40:55  ã‚¿ã‚«ã¡ã‚ƒã‚“ã‹ã‚‰è¦‹ãŸã‚‰ã‚ã„ã¤ã¯ãƒãƒ“ã ã‹ã‚‰\n",
            "ä»Taka-chançš„è§’åº¦æ¥çœ‹ï¼Œä»–æ˜¯ä¸€ä¸ªèµ¤å£ã€‚\n",
            "07:41:02  ãŸã‹ã¡ã‚ƒã‚“ã€èƒŒã®é«˜ã•ã§è¨€ã£ãŸã‚‰3ãƒ¡ãƒ¼ãƒˆãƒ«ã‚ã‚‹ã‹ã‚‰ã€ãŸã‹ã¡ã‚ƒã‚“ã€‚ãˆãˆã£?\n",
            "Taka-chanï¼Œå¦‚æœä½ è¯´é«˜ï¼Œé‚£å°±æ˜¯3ç±³ï¼ŒTaka-chanã€‚ ä»€ä¹ˆï¼Ÿ\n",
            "07:41:05  æ‡ã®æ·±ã•ã‚‚å«ã‚ã­\n",
            "åŒ…æ‹¬èƒ¸éƒ¨çš„æ·±åº¦\n",
            "07:41:12  ä¸‹ã«ã„ã‚‹ä¸‹ã«ã„ã‚‹ã¨ã„ã†ã‹æ·±ã•ãŒã™ã”ã„ã‹ã‚‰ãŒã‚“ã°ã‚Œæ·±ã•ãŒã™ã”ã„ã‹ã‚‰ãŒã‚“ã°ã‚Œ\n",
            "æˆ‘åœ¨ä¸‹é¢ï¼Œæˆ–è€…æˆ‘åœ¨ä¸‹é¢ï¼Œæ‰€ä»¥æˆ‘åœ¨å°½åŠ›è€Œä¸ºï¼Œæˆ‘æ­£åœ¨å°½åŠ›è€Œä¸ºï¼Œå› ä¸ºæ·±åº¦æ˜¯æƒŠäººçš„ã€‚\n",
            "07:41:36  ã‚¿ã‚«ãƒˆãƒ«ã€ŒæœãŒå‡„ã„ã‹ã‚‰wãŠå‰wã‚ã¯ã¯ã¯wã€ãºã‘ãŸã‚“ åœ°é¢ã«åŸ‹ã¾ã£ã¦ã‚‹ã ã‚\n",
            "å¡”å¡ç‰¹é²â€œå› ä¸ºæ—©ä¸Šå¾ˆæ£’ï¼Œä½ å•Šå“ˆå“ˆå“ˆâ€ä½©å…‹å¦ å®ƒåŸ‹åœ¨åœ°ä¸‹\n",
            "07:41:37  ãƒ–ãƒ¼ãƒ–ãƒ¼è¨€ã£ æ°·å±±ã®ä¸€è§’ã ã‹ã‚‰ä»Šè¦‹ãˆã¦ã‚‹ã\n",
            "å˜˜å˜˜ï¼Œè¿™åªæ˜¯å†°å±±ä¸€è§’ï¼Œæ‰€ä»¥ä½ ç°åœ¨å¯ä»¥çœ‹åˆ°å®ƒã€‚\n",
            "07:41:39  ãã†ãã†!æœ¬å½“ã¯3ãƒ¡ãƒ¼ãƒˆãƒ«ã²ã‚‡ã†ã–ã¿ãŸã„\n",
            "æˆ‘è®°å¾—ï¼ å®ƒçœŸçš„çœ‹èµ·æ¥åƒä¸€ä¸ª3ç±³é•¿çš„Hoozaã€‚\n",
            "07:41:41  ä¸‹ã«ã„ã£ã±ã„ã‚ã‚‹ã‚“ã ã‚ˆã“ã‚“ãªã®ã˜ã‚ƒã‚ã†ã¡ã®ç›£ç£å°ã•ã„ã‹\n",
            "ä¸‹é¢æœ‰å¾ˆå¤šï¼Œæ‰€ä»¥æˆ‘çš„å¯¼æ¼”å¾ˆå°ã€‚\n",
            "07:41:42  ã‚ã„ã¤ã¯å°ã•ã„å°ã•ã„ã€å°ã•ã„\n",
            "ä»–å¾ˆå°ï¼Œå¾ˆå°\n",
            "07:41:44  190ã—ã‹ãªã„ã‚“ã ã‹ã‚‰å°ã•ã„ã‚ˆã‚ã„ã¤190ã‚‚ã‚ã‚“ã®?\n",
            "åªæœ‰190ï¼Œæ‰€ä»¥å¾ˆå°ï¼Œä¸æ˜¯190å—ï¼Ÿ\n",
            "07:41:46  ã‚‚ã£ã¡ã‚‚ã£ã¡ã§ã‹ã„ã®ãŒæ¾æœ¬å…ˆç”Ÿã‚ã¡ã‚ƒãã¡ã‚ƒã§ã‹ã„ã‹ã‚‰ã§ã‹ã„\n",
            "å®ƒå¾ˆå¤§ï¼Œå› ä¸ºæ¾æœ¬åšå£«æç ¸äº†ï¼Œå¾ˆå¤§ã€‚\n",
            "07:41:52  â€‹â€‹â€‹ â€‹ã‚ã‚“ãªã«èƒŒé«˜ã„ã®ã«â€‹ â€‹â€‹ â€‹â€‹ â€‹ãƒãƒ¼ãƒ ãƒ¡ã‚¤ãƒˆãŒã„ã„æ‰‹ã§ä¸ŠãŒã‚‹ã¨â€‹ â€‹â€‹â€‹â€‹â€‹ â€‹ã‚³ãƒ¼ãƒ‰ã§æ±ºã‚ã‚‹ã“ã¨ãŒã§ãã‚‹â€‹ â€‹â€‹\n",
            "å³ä½¿ä½ é‚£ä¹ˆé«˜ï¼Œå½“ä½ çš„é˜Ÿå‹ç”¨å¥½ç‰Œä¸Šæ¥æ—¶ï¼Œä½ å¯ä»¥ç”¨ä»£ç æ¥å†³å®šã€‚\n",
            "07:41:55  2ãƒ¡ãƒ¼ãƒˆãƒ«ç´šã®ãã“ãã“ã®å·¨äººã ã‚ˆ\n",
            "è¿™æ˜¯ä¸€ä¸ªä¸¤ç±³é«˜çš„å·¨äººã€‚\n",
            "07:42:02  å¤§äº‹ã ã‚ˆã»ã‚“ã¨ã ã„ã„ãƒˆãƒªãƒƒã‚­ãƒ¼ã„ã¤ã‚‚ç”»é¢ã‹ã‚‰ã¯ã¿å‡ºã‚‹\n",
            "è¿™å¾ˆé‡è¦ï¼ŒçœŸçš„å¾ˆæ£˜æ‰‹æ€»æ˜¯ä¸åœ¨å±å¹•ä¸Š\n",
            "07:42:05  ğŸ–¥ãã‚“ãªé«˜ã„ã‚“ã  ğŸ”¥è¦‹ãˆã¦ã‚‹ã‹ã‚‰å¤šåˆ†\n",
            "\\ud83d\\udda5 å®ƒé‚£ä¹ˆ\\ud83d\\udd25è´µï¼Œæˆ‘å¯ä»¥çœ‹åˆ°å®ƒï¼Œæ‰€ä»¥ä¹Ÿè®¸å§ã€‚\n",
            "07:42:11  å›£ä½“å†™çœŸã¨ã‹ãƒãƒ¼ãƒ ã®å†™çœŸã‚’ å¹´ã«ä½•å›ã‹æ’®ã‚‰ã•ã‚Œã‚‹ã‚“ã ã‘ã©\n",
            "æˆ‘æ¯å¹´å¯ä»¥æ‹å‡ æ¬¡åˆå½±å’Œå›¢é˜Ÿç…§ç‰‡ã€‚\n",
            "07:42:15  ã‚ã¾ã‚Šã«ã‚‚è¨­å®šã‚„èƒŒãŒé•ã†ã‹ã‚‰ åƒ•ãŸã¡ãªã‚“ã‹ç®±ã«ä¹—ã‚‹\n",
            "å› ä¸ºè®¾ç½®å’ŒèƒŒé¢æ˜¯å¦‚æ­¤ä¸åŒï¼Œæˆ‘ä»¬å°†è¿›å…¥ç›’å­ã€‚\n",
            "07:42:21  çŸ¥ã£ã¦ã‚‹ã‚“ã ã‚ˆã­ã¯ã¯ã¯ã¯ã¯ã‚ã‹ã‚‹ã‚ˆ\n",
            "ä½ çŸ¥é“ï¼Œå“ˆå“ˆå“ˆ\n",
            "07:42:30  ãã“ã«ã­ãã‚ŒãŒå±ˆè¾±ã§ã•ãã‚ŒãŒ\n",
            "æœ‰ä¸¢è„¸\n",
            "07:42:31  åƒ•ãŸã¡ç”¨ã®ã­ãƒ¼ èƒŒã®é«˜ã•ã‚’åˆã‚ã›ã‚‹ãŸã‚ã«åƒ•ãŸã¡ç”¨ã®\n",
            "ä¸ºäº†æˆ‘ä»¬ï¼Œä¸ºäº†æˆ‘ä»¬åŒ¹é…çš„é«˜åº¦\n",
            "07:42:37  â€‹â€‹â€‹ â€‹ç®±ãŒã‚ã£ã¦ã€‚â€‹ â€‹â€‹â€‹â€‹â€‹ â€‹ãªã‚‹ã»ã©ã€‚â€‹ â€‹â€‹â€‹â€‹â€‹ â€‹ã‚ãƒ¼ã€‚â€‹ â€‹â€‹â€‹â€‹â€‹ â€‹ä¾¡æ ¼ã«ã‚‚ã•ã¿ãŸã„ã‹ã‚‰ã€‚â€‹ â€‹â€‹â€‹â€‹â€‹ â€‹ã‚ãƒ¼ã€ãã†ã€‚â€‹ â€‹â€‹\n",
            "æœ‰ä¸€ä¸ªç›’å­ã€‚æ˜ç™½äº†ã€‚å“¦ã€‚å› ä¸ºæˆ‘æƒ³æ³¨æ„ä»·æ ¼ã€‚å•Šï¼Œæ˜¯çš„ã€‚\n",
            "07:42:42  ãã†ã ã­ã€ç”»è§’æã„ãŸæ°´è°·ã‚¢ãƒ™ãƒã‚¹ã„ã¤ã‚‚ã¿ã‚“ãªç®±ã«ä¹—ã£ã¦ã‚‹å†™çœŸ\n",
            "æ²¡é”™ï¼Œä»è§†è§’ç»˜åˆ¶çš„æ°´è°·é˜¿éƒ¨å¸ƒæ–¯çš„ç…§ç‰‡æ€»æ˜¯æ¯ä¸ªäººéƒ½åœ¨ç›’å­ä¸Š\n",
            "[cli][info] Stream ended\n",
            "Interrupted! Exiting...\n",
            "[cli][info] Closing currently open stream...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ˜ä½ ä¹Ÿæ¥è¯•è¯•çœ‹å§ï¼"
      ],
      "metadata": {
        "id": "-ps3v-S2j6k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi\n",
        "!cat /proc/driver/nvidia/version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmYh9xdl_4DD",
        "outputId": "b7030603-c309-447c-f0de-4d806bf6ab90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "/bin/bash: nvidia-smi: command not found\n",
            "cat: /proc/driver/nvidia/version: No such file or directory\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}