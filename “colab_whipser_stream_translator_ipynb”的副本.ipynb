{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linglan111/colab_whipser_stream_translator/blob/main/%E2%80%9Ccolab_whipser_stream_translator_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 使用colab云端运行自动字幕程序\n"
      ],
      "metadata": {
        "id": "Lbja1jB3vDOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "第一步从github上将要用到的项目复制下来\n",
        "这里前面的!是为了告诉colab\n",
        "**这一步我们用的是shell命令而不是python语句**"
      ],
      "metadata": {
        "id": "dSJ6EpRAbRZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fortypercnt/stream-translator.git"
      ],
      "metadata": {
        "id": "JyWu-c57JdGH",
        "outputId": "fd148b27-77cc-4775-a800-84a82d320d91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stream-translator'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 69 (delta 34), reused 29 (delta 29), pack-reused 31\u001b[K\n",
            "Unpacking objects: 100% (69/69), 1.19 MiB | 1.04 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "下一步安装依赖"
      ],
      "metadata": {
        "id": "uaA0w3BkdJ4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/stream-translator/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dz0JHOwwdHUH",
        "outputId": "140fb97a-6c61-42a3-e555-988d68b437d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Collecting git+https://github.com/openai/whisper.git (from -r /content/stream-translator/requirements.txt (line 8))\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-y8d0djf_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-y8d0djf_\n",
            "  Resolved https://github.com/openai/whisper.git to commit 248b6cb124225dd263bb9bd32d060b6517e067f8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r /content/stream-translator/requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /content/stream-translator/requirements.txt (line 2)) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from -r /content/stream-translator/requirements.txt (line 3)) (9.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r /content/stream-translator/requirements.txt (line 5)) (2.0.1+cu118)\n",
            "Collecting transformers>=4.19.0 (from -r /content/stream-translator/requirements.txt (line 6))\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0 (from -r /content/stream-translator/requirements.txt (line 7))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting streamlink (from -r /content/stream-translator/requirements.txt (line 9))\n",
            "  Downloading streamlink-5.5.1-py3-none-any.whl (362 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.5/362.5 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->-r /content/stream-translator/requirements.txt (line 7)) (0.18.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/stream-translator/requirements.txt (line 5)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/stream-translator/requirements.txt (line 5)) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/stream-translator/requirements.txt (line 5)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/stream-translator/requirements.txt (line 5)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/stream-translator/requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r /content/stream-translator/requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r /content/stream-translator/requirements.txt (line 5)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r /content/stream-translator/requirements.txt (line 5)) (16.0.6)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6))\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6))\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314->-r /content/stream-translator/requirements.txt (line 8)) (0.56.4)\n",
            "Collecting tiktoken==0.3.3 (from openai-whisper==20230314->-r /content/stream-translator/requirements.txt (line 8))\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from streamlink->-r /content/stream-translator/requirements.txt (line 9)) (2023.5.7)\n",
            "Collecting isodate (from streamlink->-r /content/stream-translator/requirements.txt (line 9))\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml<5.0,>=4.6.4 in /usr/local/lib/python3.10/dist-packages (from streamlink->-r /content/stream-translator/requirements.txt (line 9)) (4.9.2)\n",
            "Collecting pycountry (from streamlink->-r /content/stream-translator/requirements.txt (line 9))\n",
            "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome<4,>=3.4.3 (from streamlink->-r /content/stream-translator/requirements.txt (line 9))\n",
            "  Downloading pycryptodome-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from streamlink->-r /content/stream-translator/requirements.txt (line 9)) (1.7.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from streamlink->-r /content/stream-translator/requirements.txt (line 9)) (1.26.16)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from streamlink->-r /content/stream-translator/requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.19.0->-r /content/stream-translator/requirements.txt (line 6)) (3.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate->streamlink->-r /content/stream-translator/requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r /content/stream-translator/requirements.txt (line 5)) (2.1.3)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314->-r /content/stream-translator/requirements.txt (line 8)) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314->-r /content/stream-translator/requirements.txt (line 8)) (67.7.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r /content/stream-translator/requirements.txt (line 5)) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper, pycountry\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798075 sha256=f9a3878d68ed37adb292c4f0d59293da672693a0f75665d7634d8b849776739d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m4ezgvzl/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "  Building wheel for pycountry (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681832 sha256=f03709e82c6b36755bf2f3fc083f5488912bcea2d3a327f9c6cbab89e4f028b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/57/cc/290c5252ec97a6d78d36479a3c5e5ecc76318afcb241ad9dbe\n",
            "Successfully built openai-whisper pycountry\n",
            "Installing collected packages: tokenizers, safetensors, pycryptodome, pycountry, isodate, ffmpeg-python, tiktoken, streamlink, huggingface-hub, transformers, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.15.1 isodate-0.6.1 openai-whisper-20230314 pycountry-22.3.5 pycryptodome-3.18.0 safetensors-0.3.1 streamlink-5.5.1 tiktoken-0.3.3 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#修改工作"
      ],
      "metadata": {
        "id": "Z6_hXwR9ajWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里有一个小坑\n",
        "我们先尝试不做任何改动直接运行程序\n",
        "会发现在模型下载好之后直接报错找不到指定文件\n",
        "ValueError: The provided filename silero_vad.jit does not exist"
      ],
      "metadata": {
        "id": "G5ltjG3Idz8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 stream-translator/translator.py https://www.youtube.com/watch?v=swe6ea_9P2s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs8mszjbd6zg",
        "outputId": "8e7b6bb9-5f50-409f-a3f8-af22026d2bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "100%|███████████████████████████████████████| 461M/461M [00:09<00:00, 50.7MiB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"stream-translator/translator.py\", line 226, in <module>\n",
            "    cli()\n",
            "  File \"stream-translator/translator.py\", line 222, in cli\n",
            "    main(url, **args)\n",
            "  File \"stream-translator/translator.py\", line 117, in main\n",
            "    vad = VAD()\n",
            "  File \"/content/stream-translator/vad.py\", line 9, in __init__\n",
            "    self.model = init_jit_model(\"silero_vad.jit\")\n",
            "  File \"/content/stream-translator/vad.py\", line 20, in init_jit_model\n",
            "    model = torch.jit.load(model_path, map_location=device)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/jit/_serialization.py\", line 152, in load\n",
            "    raise ValueError(\"The provided filename {} does not exist\".format(f))  # type: ignore[str-bytes-safe]\n",
            "ValueError: The provided filename silero_vad.jit does not exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "点击左侧的文件夹📂\n",
        "选择stream-translator\n",
        "右键silero_vad.jit获取文件地址\n",
        "双击vad.py可以看到右侧打开了一个在线编辑页面\n",
        "我们在第9行将init_jit_model后面括号里的内容\n",
        "改为刚才复制的文件地址\n",
        "然后ctrl+s保存后关闭文件\n",
        "这里是因为colab直接git下来的项目\n",
        "运行的时候这里会出现无法指定到正确路径的问题\n",
        "所以需要手动改为绝对路径"
      ],
      "metadata": {
        "id": "zuHOPp8catS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#开始运行"
      ],
      "metadata": {
        "id": "jeIZ3okhao8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "网址改为你想要实时转录的直播\n",
        "理论上来说只要streamlink支持的网站都可以"
      ],
      "metadata": {
        "id": "vx5Y_Mf5cXs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 stream-translator/translator.py https://www.youtube.com/watch?v=HL5WsJBsp4o"
      ],
      "metadata": {
        "id": "scuUKqmEV7-U",
        "outputId": "da53f943-bd88-4193-d258-9887bdaaee62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "100%|███████████████████████████████████████| 461M/461M [00:07<00:00, 63.5MiB/s]\n",
            "Opening stream...\n",
            "[cli][info] streamlink is running as root! Be careful!\n",
            "[cli][info] Found matching plugin youtube for URL https://www.youtube.com/watch?v=HL5WsJBsp4o\n",
            "[cli][info] Available streams: 144p (worst), 240p, 360p, 480p, 720p, 1080p (best)\n",
            "[cli][info] Opening stream: 1080p (hls)\n",
            "06:05:43 (ja)  Oh no! Wait, isn't this a road car?\n",
            "06:05:44 (ja)  Next, I'm the king! The queen!\n",
            "06:05:49 (ja)  You're pretty cakey! I'll deal with you! Ok!\n",
            "06:05:54 (ja)  How can I have anger on women? How can I have hope on women?\n",
            "06:06:05 (ja)  Yeah, that's right​\n",
            "06:06:07 (ja)  Naoto-kun! Naoto-kun! Naoto-kun! Naoto-kun!\n",
            "06:06:07 (ja)  What?\n",
            "06:06:09 (ja)  If I talk to you, I'll let you know something.\n",
            "06:06:10 (ja)  I don't care. I don't care. I don't care.\n",
            "06:06:16 (ja)  It's your fault!\n",
            "06:06:20 (ja)  What is it?\n",
            "06:06:26 (ja) \n",
            "06:06:31 (ja)  Yeah.\n",
            "06:06:39 (ja)  That's awesome!\n",
            "06:06:40 (ja)  I feel like I'm in the middle of something. You're right, it's like you're in the middle of something.\n",
            "06:06:46 (ja)  In the past, there was no scientific research.\n",
            "06:06:50 (ja)  Hmm.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "忽略结尾因手动暂停而产生的报错信息\n",
        "转录出的结果看起来还是有些怪怪的\n",
        "我们一个个解决\n",
        "\n",
        "\n",
        "*   **转录出来的东西是英文**\n",
        "这是因为stream_translator的作者默认设置的是开启英文翻译\n",
        "运行的时候需要在后面加上参数 --task transcribe\n",
        "*   **有时候识别出来的语种并不是主播说的**\n",
        "语言参数默认为auto\n",
        "也就是每一句都是自动识别语种\n",
        "更改为指定语言可以解决这一问题\n",
        "*   **不够精准**\n",
        "模型参数默认为small\n",
        "既然白嫖colab的GPU，我们可以修改为medium甚至large😀\n",
        " *实际转录中出现了设置模型过大的时候无法正常转录的情况初步判断应该是内存不够的问题*\n",
        "*   **导入的流是1080P担心影响转录速度**\n",
        "正常来说ffmpeg会自动分离出音频流所以影响不大\n",
        "如果还是怕1080P的直播分片下载会卡\n",
        "这里可以手动去配置文件修改为worst拉取144p的流\n",
        "作者默认的audio_only参数对于youtube直播是无效的\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jBPFRC43fD5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在上一次曾经打开的文件夹里找到translator.py文件\n",
        "双击打开定位到167行def cli()这个函数里\n",
        "里面所有default对应的值就是默认值\n",
        "按照上面的需求我们可以按照如下修改\n",
        "--model medium\n",
        "--task transcribe\n",
        "--language Japanese（按照实际需求）\n",
        "--preferred_quality worst\n",
        "重新跑一遍试试看吧！\n",
        "注意加入新模型的时候要先下载"
      ],
      "metadata": {
        "id": "tvBpp56BhxSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!pip install \"faster-whisper @ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz\"\n",
        "!ct2-transformers-converter --model openai/whisper-large-v2 --output_dir whisper-large-v2-ct2 \\\n",
        "    --copy_files tokenizer.json --quantization float16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ftx7ROuX4vf",
        "outputId": "1123ea61-2963-40fa-ccfb-e9ddb5f25019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz\n",
            "  Downloading https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz\n",
            "\u001b[2K     \u001b[32m/\u001b[0m \u001b[32m2.9 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av==10.* (from faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctranslate2<4,>=3.10 (from faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading ctranslate2-3.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (0.15.1)\n",
            "Requirement already satisfied: tokenizers==0.13.* in /usr/local/lib/python3.10/dist-packages (from faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (0.13.3)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m118.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.10->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (1.22.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.10->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (4.6.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (23.1)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (1.11.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.13->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper@ https://github.com/guillaumekln/faster-whisper/archive/refs/heads/master.tar.gz) (1.3.0)\n",
            "Building wheels for collected packages: faster-whisper\n",
            "  Building wheel for faster-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for faster-whisper: filename=faster_whisper-0.6.0-py3-none-any.whl size=1537994 sha256=daa3484e565befef20d9c389b0befbff5d2a93bb30c80da5f73ee53c27c28ae2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zzl3xly3/wheels/b6/35/41/e289a1c8f68133f6b89dab0a3883dd5183cab41a321567010d\n",
            "Successfully built faster-whisper\n",
            "Installing collected packages: av, humanfriendly, ctranslate2, coloredlogs, onnxruntime, faster-whisper\n",
            "Successfully installed av-10.0.0 coloredlogs-15.0.1 ctranslate2-3.16.0 faster-whisper-0.6.0 humanfriendly-10.0 onnxruntime-1.15.1\n",
            "Downloading (…)lve/main/config.json: 1.99kB [00:00, 7.59MB/s]\n",
            "Downloading pytorch_model.bin: 100% 6.17G/6.17G [00:35<00:00, 175MB/s]\n",
            "Downloading (…)neration_config.json: 3.51kB [00:00, 1.12MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 800/800 [00:00<00:00, 1.64MB/s]\n",
            "Downloading (…)olve/main/vocab.json: 836kB [00:00, 1.33MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 2.20MB [00:00, 2.53MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 494kB [00:00, 1.14MB/s]\n",
            "Downloading (…)main/normalizer.json: 52.7kB [00:00, 29.2MB/s]\n",
            "Downloading (…)in/added_tokens.json: 2.08kB [00:00, 8.05MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 2.08kB [00:00, 7.23MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stream-translator/\n",
        "!git clone https://github.com/neverneverendup/Translator.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gggy8EWfMqZy",
        "outputId": "222fa4d9-e13e-4196-907b-8bb493305a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stream-translator\n",
            "Cloning into 'Translator'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 34 (delta 15), reused 7 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), 14.95 KiB | 1.36 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!python3 stream-translator/translator.py https://www.youtube.com/watch?v=y5M6OZKhJjI --model large --task transcribe --language ja \\\n",
        "  --use_faster_whisper --faster_whisper_model_path /content/whisper-large-v2-ct2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES05tKOuic4X",
        "outputId": "c967bb95-b27e-4ee9-a032-1a9c718bc641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Loading model...\n",
            "Opening stream...\n",
            "[cli][info] streamlink is running as root! Be careful!\n",
            "[cli][info] Found matching plugin youtube for URL https://www.youtube.com/watch?v=y5M6OZKhJjI\n",
            "[cli][info] Available streams: 144p (worst), 240p, 360p, 480p, 720p, 1080p (best)\n",
            "[cli][info] Opening stream: 1080p (hls)\n",
            "07:39:59  いやーリゼ様ずっとしんどかった本当に嘘だった\n",
            "不，里泽萨玛真的是谎言。\n",
            "07:40:01  【はじめしゃちょーエンディング】\n",
            "【初沙町结局】\n",
            "07:40:05  ん?ニックネームの効果みたいなああ\n",
            "嗯？ 这就像昵称的效果。\n",
            "07:40:13  あるかもしれない出たその理論理論あるあるある名前から理論\n",
            "可能有一种理论认为理论是从一些名字中出来的\n",
            "07:40:16  しんきゅん 幸運族がしんきゅん 強いからしんきゅん 幸運しんきゅん 幸運族\n",
            "新均幸运部落 新均强卡拉 新均 祝你好运 新均幸运部落\n",
            "07:40:21  でもうちの監督、キョウウンですけどもって名前変えてて2位だったかな\n",
            "但是我的教练Kyoun改了名字，获得了第二名。\n",
            "07:40:33  ぺけたん いやそれだからなかったら4位だからぺけたん 笑\n",
            "佩克坦 不，如果不是这样，我会排在第四位，哈哈。\n",
            "07:40:35  あいつをそんな、上に見なくていいよ、あいつを\n",
            "你不必那样看着他，\n",
            "07:40:38  あいつは実力が4位だからこの動画の字幕は視聴者によって作成されました。\n",
            "他排名第四，所以这个视频的字幕是由观众创建的。\n",
            "07:40:42  あの名前のおかげでうちの監督に厳しいよ\n",
            "因为这个名字，我对我的教练很严厉。\n",
            "07:40:45  赤ちゃんぐらいしか厳しくする人いないから\n",
            "因为没有人像婴儿一样严格\n",
            "07:40:51  みんなもってぃに甘いから\n",
            "因为每个人都那么甜蜜\n",
            "07:40:55  タカちゃんから見たらあいつはチビだから\n",
            "从Taka-chan的角度来看，他是一个赤壁。\n",
            "07:41:02  たかちゃん、背の高さで言ったら3メートルあるから、たかちゃん。ええっ?\n",
            "Taka-chan，如果你说高，那就是3米，Taka-chan。 什么？\n",
            "07:41:05  懐の深さも含めね\n",
            "包括胸部的深度\n",
            "07:41:12  下にいる下にいるというか深さがすごいからがんばれ深さがすごいからがんばれ\n",
            "我在下面，或者我在下面，所以我在尽力而为，我正在尽力而为，因为深度是惊人的。\n",
            "07:41:36  タカトル「朝が凄いからwお前wあはははw」ぺけたん 地面に埋まってるだろ\n",
            "塔卡特鲁“因为早上很棒，你啊哈哈哈”佩克坦 它埋在地下\n",
            "07:41:37  ブーブー言っ 氷山の一角だから今見えてるぞ\n",
            "嘘嘘，这只是冰山一角，所以你现在可以看到它。\n",
            "07:41:39  そうそう!本当は3メートルひょうざみたい\n",
            "我记得！ 它真的看起来像一个3米长的Hooza。\n",
            "07:41:41  下にいっぱいあるんだよこんなのじゃあうちの監督小さいか\n",
            "下面有很多，所以我的导演很小。\n",
            "07:41:42  あいつは小さい小さい、小さい\n",
            "他很小，很小\n",
            "07:41:44  190しかないんだから小さいよあいつ190もあんの?\n",
            "只有190，所以很小，不是190吗？\n",
            "07:41:46  もっちもっちでかいのが松本先生めちゃくちゃでかいからでかい\n",
            "它很大，因为松本博士搞砸了，很大。\n",
            "07:41:52  ​​​ ​あんなに背高いのに​ ​​ ​​ ​チームメイトがいい手で上がると​ ​​​​​ ​コードで決めることができる​ ​​\n",
            "即使你那么高，当你的队友用好牌上来时，你可以用代码来决定。\n",
            "07:41:55  2メートル級のそこそこの巨人だよ\n",
            "这是一个两米高的巨人。\n",
            "07:42:02  大事だよほんとだいいトリッキーいつも画面からはみ出る\n",
            "这很重要，真的很棘手总是不在屏幕上\n",
            "07:42:05  🖥そんな高いんだ 🔥見えてるから多分\n",
            "\\ud83d\\udda5 它那么\\ud83d\\udd25贵，我可以看到它，所以也许吧。\n",
            "07:42:11  団体写真とかチームの写真を 年に何回か撮らされるんだけど\n",
            "我每年可以拍几次合影和团队照片。\n",
            "07:42:15  あまりにも設定や背が違うから 僕たちなんか箱に乗る\n",
            "因为设置和背面是如此不同，我们将进入盒子。\n",
            "07:42:21  知ってるんだよねはははははわかるよ\n",
            "你知道，哈哈哈\n",
            "07:42:30  そこにねそれが屈辱でさそれが\n",
            "有丢脸\n",
            "07:42:31  僕たち用のねー 背の高さを合わせるために僕たち用の\n",
            "为了我们，为了我们匹配的高度\n",
            "07:42:37  ​​​ ​箱があって。​ ​​​​​ ​なるほど。​ ​​​​​ ​あー。​ ​​​​​ ​価格にもさみたいから。​ ​​​​​ ​あー、そう。​ ​​\n",
            "有一个盒子。明白了。哦。因为我想注意价格。啊，是的。\n",
            "07:42:42  そうだね、画角描いた水谷アベバスいつもみんな箱に乗ってる写真\n",
            "没错，从视角绘制的水谷阿部布斯的照片总是每个人都在盒子上\n",
            "[cli][info] Stream ended\n",
            "Interrupted! Exiting...\n",
            "[cli][info] Closing currently open stream...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "😎你也来试试看吧！"
      ],
      "metadata": {
        "id": "-ps3v-S2j6k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi\n",
        "!cat /proc/driver/nvidia/version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmYh9xdl_4DD",
        "outputId": "b7030603-c309-447c-f0de-4d806bf6ab90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "/bin/bash: nvidia-smi: command not found\n",
            "cat: /proc/driver/nvidia/version: No such file or directory\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}